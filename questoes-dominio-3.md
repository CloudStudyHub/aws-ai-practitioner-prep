# üîπ Dom√≠nio 3 ‚Äì Aplica√ß√£o de Modelos de Base: Quest√µes

### Tarefa 3.1: Design de Aplica√ß√µes e Crit√©rios de Sele√ß√£o

1. Qual crit√©rio avalia o custo por token, de hospedagem e ajuste fino de um modelo de base?
- [ ] Modalidade
- [ ] Custo e Complexidade
- [ ] Lat√™ncia
- [ ] Janela de Contexto

2. Um modelo que processa texto e imagem simultaneamente √© considerado:
- [ ] Unimodal
- [ ] Multimodal
- [ ] Apenas texto
- [ ] Apenas imagem

3. A velocidade de resposta de um modelo √© avaliada pelo crit√©rio:
- [ ] Capacidade de Personaliza√ß√£o
- [ ] Lat√™ncia
- [ ] Tamanho da Janela de Contexto
- [ ] Suporte a Idiomas

4. O par√¢metro que define a quantidade m√°xima de tokens processados em uma chamada √©:
- [ ] Temperatura
- [ ] Max Tokens
- [ ] Janela de Contexto
- [ ] Modalidade

5. Qual crit√©rio verifica se um modelo permite fine-tuning para dom√≠nios espec√≠ficos?
- [ ] Suporte a Idiomas
- [ ] Capacidade de Personaliza√ß√£o
- [ ] Custo e Complexidade
- [ ] Lat√™ncia

6. Qual crit√©rio avalia se o modelo suporta os idiomas necess√°rios para a aplica√ß√£o?
- [ ] Suporte a Idiomas
- [ ] Modalidade
- [ ] Janela de Contexto
- [ ] Temperatura

---

### Par√¢metros de Infer√™ncia e Gera√ß√£o de Respostas

7. O que a temperatura (temperature) controla em um modelo de IA?
- [ ] Quantidade de tokens processados
- [ ] Aleatoriedade da resposta
- [ ] Velocidade de infer√™ncia
- [ ] Tipo de dado processado

8. Uma temperatura baixa (ex: 0.1) gera respostas:
- [ ] Criativas e inesperadas
- [ ] Previs√≠veis e consistentes
- [ ] Sempre curtas
- [ ] Focadas apenas em texto

9. Qual par√¢metro define o comprimento m√°ximo da resposta gerada pelo modelo?
- [ ] Temperature
- [ ] Max Tokens
- [ ] Janela de Contexto
- [ ] Modalidade

---

### Tarefa 3.1: Gera√ß√£o Aumentada de Recupera√ß√£o (RAG)

10. O principal objetivo da t√©cnica RAG √©:
- [ ] Reduzir custo de treinamento
- [ ] Acessar conhecimento externo atualizado
- [ ] Evitar o uso de embeddings
- [ ] Substituir o ajuste fino

11. Qual servi√ßo AWS simplifica a implementa√ß√£o de RAG?
- [ ] Amazon SageMaker
- [ ] Knowledge Bases for Amazon Bedrock
- [ ] Amazon Neptune
- [ ] AWS Lambda

12. Em RAG, qual tipo de banco √© usado para armazenar embeddings dos documentos?
- [ ] Banco de dados relacional ou vetorial
- [ ] Banco de dados em cache
- [ ] Banco de dados NoSQL sem vetores
- [ ] Apenas arquivos CSV

13. Qual √© o principal benef√≠cio de RAG para respostas de IA?
- [ ] Reduz a lat√™ncia do modelo
- [ ] Evita alucina√ß√µes usando dados confi√°veis
- [ ] Substitui totalmente o modelo pr√©-treinado
- [ ] Aumenta a temperatura automaticamente

---

### Tarefa 3.1: Agentes (Agents)

14. Um agente √© diferente de um LLM porque:
- [ ] Apenas responde perguntas
- [ ] Pode executar a√ß√µes e orquestrar tarefas externas
- [ ] N√£o precisa de prompts
- [ ] Funciona sem dados

15. Qual servi√ßo AWS permite criar e gerenciar agentes?
- [ ] Amazon Bedrock
- [ ] Agents for Amazon Bedrock
- [ ] Amazon Q
- [ ] Amazon SageMaker

16. Qual seria um exemplo de a√ß√£o que um agente pode realizar?
- [ ] Responder perguntas triviais
- [ ] Planejar f√©rias buscando voos e hot√©is
- [ ] Apenas resumir texto
- [ ] Treinar outro modelo

---

### Tarefa 3.2: Engenharia de Prompts

17. Qual t√©cnica de prompt pede ao modelo realizar uma tarefa sem fornecer exemplos?
- [ ] Zero-shot Prompting
- [ ] Few-shot Prompting
- [ ] Chain-of-Thought
- [ ] Prompts Negativos

18. Qual t√©cnica inclui exemplos de entrada e sa√≠da para guiar o modelo?
- [ ] Zero-shot Prompting
- [ ] Few-shot Prompting
- [ ] Chain-of-Thought
- [ ] Prompts Negativos

19. Chain-of-Thought (CoT) instrui o modelo a:
- [ ] Ignorar os exemplos no prompt
- [ ] Decompor seu racioc√≠nio passo a passo
- [ ] Aumentar a temperatura
- [ ] Reduzir tokens de sa√≠da

20. Prompts Negativos s√£o usados para:
- [ ] Aumentar criatividade
- [ ] Indicar o que o modelo deve evitar gerar
- [ ] Ajustar a temperatura
- [ ] Escolher a modalidade do modelo

21. Qual risco envolve um usu√°rio mal-intencionado inserindo instru√ß√µes no prompt para desviar o comportamento do modelo?
- [ ] Prompt Hijacking
- [ ] Jailbreaking
- [ ] Exposi√ß√£o de Dados
- [ ] Prompt Injection

22. Qual amea√ßa busca contornar filtros de seguran√ßa do modelo para gerar conte√∫do proibido?
- [ ] Prompt Hijacking
- [ ] Jailbreaking
- [ ] Exposi√ß√£o de Dados
- [ ] Prompt Injection

23. Qual risco envolve vazar informa√ß√µes sens√≠veis inclu√≠das no prompt enviado a uma API?
- [ ] Prompt Hijacking
- [ ] Jailbreaking
- [ ] Exposi√ß√£o de Dados
- [ ] Prompt Injection

24. Ataques que manipulam entradas n√£o confi√°veis para gerar respostas maliciosas s√£o chamados de:
- [ ] Prompt Hijacking
- [ ] Jailbreaking
- [ ] Exposi√ß√£o de Dados
- [ ] Prompt Injection

---

### Tarefa 3.3: Treinamento e Ajuste Fino

25. Qual fase inicial de treinamento massivo faz o modelo aprender padr√µes de linguagem e fatos gerais?
- [ ] Fine-Tuning
- [ ] Pr√©-treinamento
- [ ] In-context Learning
- [ ] RAG

26. Qual t√©cnica adapta um modelo pr√©-treinado a um conjunto de dados espec√≠fico de uma tarefa?
- [ ] Fine-Tuning
- [ ] Pr√©-treinamento
- [ ] Zero-shot Prompting
- [ ] Few-shot Prompting

27. O que √© Catastrophic Forgetting (Esquecimento Catastr√≥fico)?
- [ ] Perda de dados no banco
- [ ] Ajuste fino que degrada desempenho em tarefas antigas
- [ ] Erro de infer√™ncia do modelo
- [ ] Problema de embeddings

28. PEFT (Parameter-Efficient Fine-Tuning) tem como objetivo:
- [ ] Treinar todos os pesos do modelo
- [ ] Treinar apenas pequenos par√¢metros para reduzir custo e mem√≥ria
- [ ] Substituir embeddings
- [ ] Aumentar a temperatura

29. LORA √© uma t√©cnica de:
- [ ] Engenharia de prompts
- [ ] PEFT (Ajuste Fino Eficiente de Par√¢metros)
- [ ] RAG
- [ ] Agentes

30. RLHF (Reinforcement Learning from Human Feedback) √© usado para:
- [ ] Ajustar modelo de acordo com prefer√™ncias humanas
- [ ] Substituir o pr√©-treinamento
- [ ] Treinar embeddings
- [ ] Medir lat√™ncia
