# üîπ Dom√≠nio 3: Aplica√ß√£o de Modelos de Base (Foundation Models)

Este dom√≠nio aborda as decis√µes pr√°ticas de design, engenharia de prompts, personaliza√ß√£o e avalia√ß√£o de modelos de base para criar aplica√ß√µes eficazes e alinhadas aos objetivos de neg√≥cio.

---

## Tarefa 3.1: Descrever as considera√ß√µes sobre design de aplica√ß√µes

Esta se√ß√£o foca em como escolher, configurar e arquitetar solu√ß√µes usando modelos de base pr√©-treinados.

### Crit√©rios de Sele√ß√£o para Modelos Pr√©-treinados

A escolha do modelo correto √© fundamental e envolve analisar diversas caracter√≠sticas para encontrar o equil√≠brio ideal entre desempenho e custo.

- **Custo e Complexidade:** Avalia o custo por token, de hospedagem e de ajuste fino. Modelos mais complexos e maiores geralmente s√£o mais capazes, mas tamb√©m mais caros e lentos.

- **Modalidade:** Determina se o modelo trabalha com um √∫nico tipo de dado (texto, imagem) ou se √© multimodal, ou seja, capaz de processar m√∫ltiplos tipos de dados combinados.

- **Lat√™ncia e Velocidade de Infer√™ncia:** Mede a rapidez com que o modelo responde. √â um crit√©rio cr√≠tico para aplica√ß√µes em tempo real, como chatbots interativos ou assistentes em ve√≠culos aut√¥nomos.

- **Tamanho da Janela de Contexto (Context Window):** Refere-se √† quantidade m√°xima de tokens que o modelo pode processar em uma √∫nica chamada. Um contexto maior permite analisar documentos mais longos ou manter conversas mais complexas.

- **Suporte a Idiomas:** Verifica se o modelo suporta os idiomas necess√°rios para a aplica√ß√£o.

- **Capacidade de Personaliza√ß√£o:** Confirma se o modelo permite ajuste fino (fine-tuning) para adapt√°-lo a tarefas espec√≠ficas.

### Par√¢metros de Infer√™ncia: Controlando a Resposta do Modelo

S√£o configura√ß√µes usadas no momento da chamada do modelo (infer√™ncia) para influenciar o estilo e o formato da resposta gerada.

- **Temperatura (Temperature):** Controla a aleatoriedade da resposta.  
  - Temperatura Baixa (ex: 0.1): Gera respostas mais previs√≠veis, focadas e consistentes. Ideal para tarefas factuais como extra√ß√£o de informa√ß√£o ou resumo.  
  - Temperatura Alta (ex: 0.9): Produz respostas mais criativas, diversas e, por vezes, inesperadas. √ötil para tarefas como escrita de marketing ou brainstorming.

- **Tamanho M√°ximo da Sa√≠da (Max Tokens):** Define o comprimento m√°ximo da resposta gerada. Um valor muito baixo pode fazer com que a resposta seja cortada no meio.

---

### Gera√ß√£o Aumentada de Recupera√ß√£o (RAG - Retrieval-Augmented Generation)

√â uma t√©cnica que aprimora os LLMs, permitindo que eles acessem e utilizem conhecimento de uma fonte externa e atualizada durante a gera√ß√£o da resposta.

- **Conceito e Funcionamento:** Em vez de depender apenas do seu conhecimento interno (que pode estar desatualizado), o sistema primeiro busca informa√ß√µes relevantes em uma base de conhecimento externa (como documentos da empresa) e, em seguida, insere essas informa√ß√µes no prompt como contexto para o LLM gerar a resposta.

- **Benef√≠cios:** Ajuda a evitar alucina√ß√µes, fundamentando as respostas em dados confi√°veis, e resolve o problema de conhecimento desatualizado do modelo.

- **Implementa√ß√£o na AWS:** O recurso **Knowledge Bases for Amazon Bedrock** simplifica a implementa√ß√£o de RAG. O processo requer um banco de dados de vetores para armazenar os embeddings dos documentos. Servi√ßos AWS compat√≠veis incluem:  
  - **Amazon OpenSearch Service:** Com a funcionalidade k-NN (k-Nearest Neighbors ou k-vizinhos mais pr√≥ximos), um m√©todo para busca de similaridade em dados vetoriais.  
  - **Amazon Aurora e Amazon RDS (PostgreSQL):** Com a extens√£o pgvector, que habilita a busca por similaridade de vetores no PostgreSQL.  
  - **Amazon Neptune e Amazon DocumentDB:** Com capacidade de busca vetorial.

---

### Agentes (Agents)

S√£o sistemas que usam um LLM como um "c√©rebro" para realizar tarefas complexas de m√∫ltiplas etapas que exigem intera√ß√£o com sistemas externos.

- **Conceito e Fun√ß√£o:** Enquanto um LLM pode responder a uma pergunta, um agente pode executar uma a√ß√£o no mundo real. Ele decomp√µe um pedido complexo (ex: "planeje minhas f√©rias") em tarefas menores, chama APIs (para buscar voos, reservar hot√©is) e orquestra o fluxo de trabalho at√© a conclus√£o.

- **Servi√ßo AWS:** **Agents for Amazon Bedrock** √© a capacidade que permite criar e gerenciar esses agentes para automatizar processos de neg√≥cio.

---

### Comparativo de Custos e Esfor√ßo de Personaliza√ß√£o

Existem diferentes n√≠veis de personaliza√ß√£o, cada um com um custo e complexidade associados:

- **Pr√©-treinamento (do zero):** Custo mais alto. Raramente necess√°rio, exige enormes volumes de dados e poder computacional, mas oferece personaliza√ß√£o total.  

- **Ajuste Fino (Fine-Tuning):** Custo alto. Adapta um modelo pr√©-treinado a um dom√≠nio espec√≠fico (ex: jur√≠dico, m√©dico) usando um dataset menor e rotulado. Melhora significativamente o desempenho em tarefas de nicho.

- **RAG:** Custo moderado. O custo vem do armazenamento de vetores e chamadas ao banco de dados, mas √© muito mais barato que o ajuste fino. Excelente para fornecer conhecimento factual e atualizado.

- **Aprendizado em Contexto (In-context learning / Prompting):** Custo mais baixo. A "personaliza√ß√£o" ocorre a cada chamada de API, fornecendo exemplos e contexto diretamente no prompt (few-shot prompting). N√£o altera os pesos do modelo, apenas guia sua resposta.

---

## Tarefa 3.2: Escolher t√©cnicas eficazes de engenharia de prompts

√â a pr√°tica de criar e otimizar os prompts para guiar o modelo a gerar a resposta mais apropriada e de alta qualidade.

### T√©cnicas Comuns de Engenharia de Prompts

- **Zero-shot Prompting:** Pedir ao modelo para realizar uma tarefa sem fornecer nenhum exemplo em que se basear.

- **Few-shot Prompting:** Incluir um ou alguns exemplos ("shots") de entrada e sa√≠da desejada diretamente no prompt para ajudar o modelo a entender o padr√£o e calibrar sua resposta.

- **Cadeia de Pensamento (CoT - Chain-of-Thought):** Instruir o modelo a "pensar passo a passo" ou detalhar seu racioc√≠nio antes de dar a resposta final. Essa t√©cnica melhora drasticamente o desempenho em problemas l√≥gicos e matem√°ticos.

- **Prompts Negativos:** Instru√ß√µes sobre o que o modelo deve evitar gerar em sua resposta.

### Riscos e Amea√ßas de Seguran√ßa

- **Exposi√ß√£o de Dados:** Risco de vazar informa√ß√µes sens√≠veis se forem inclu√≠das no prompt enviado a uma API de terceiros.

- **Prompt Hijacking (Sequestro):** Um usu√°rio mal-intencionado insere instru√ß√µes em uma parte do prompt para fazer o modelo ignorar as instru√ß√µes originais e executar uma tarefa diferente e n√£o intencional.

- **Jailbreaking:** Tentativas de criar prompts que contornam os filtros de seguran√ßa e as barreiras de prote√ß√£o (guardrails) do modelo para gerar conte√∫do proibido ou malicioso.

---

## Tarefa 3.3: Descrever o processo de treinamento e ajuste fino

Esta se√ß√£o aborda como os modelos s√£o treinados e adaptados para tarefas espec√≠ficas.

- **Pr√©-treinamento:** Fase inicial e massiva onde o modelo aprende padr√µes de linguagem, fatos e racioc√≠nio a partir de um dataset geral e n√£o estruturado, como a internet.

- **Ajuste Fino (Fine-Tuning):** Um segundo est√°gio de treinamento supervisionado. Ele adapta o modelo pr√©-treinado a um conjunto de dados menor e espec√≠fico de uma tarefa ou dom√≠nio (ex: documentos jur√≠dicos) para melhorar seu desempenho.

- **Aprendizado por Transfer√™ncia (Transfer Learning):** √â o conceito geral que fundamenta o ajuste fino, onde o conhecimento de um modelo pr√©-treinado √© "transferido" para uma nova tarefa.

- **Limita√ß√£o - Catastrophic Forgetting (Esquecimento Catastr√≥fico):** O ajuste fino em uma √∫nica tarefa pode fazer com que o modelo "esque√ßa" ou degrade seu desempenho em outras tarefas que ele sabia executar.

- **PEFT (Parameter-Efficient Fine-Tuning ou Ajuste Fino Eficiente de Par√¢metros):** Um conjunto de t√©cnicas que congelam a maioria dos pesos do LLM original e treinam apenas um pequeno n√∫mero de novos par√¢metros. Isso reduz significativamente os custos de computa√ß√£o e mem√≥ria.  

  - **LORA (Low-Rank Adaptation ou Adapta√ß√£o de Baixo Rank):** Uma t√©cnica popular de PEFT.

- **RLHF (Reinforcement Learning from Human Feedback ou Aprendizado por Refor√ßo com Feedback Humano):** Uma t√©cnica avan√ßada para alinhar o comportamento do modelo com as prefer√™ncias humanas, tornando-o mais √∫til e seguro. Humanos classificam as respostas do modelo, e um "modelo de recompensa" √© treinado com base nessas prefer√™ncias para, em seguida, ajustar o LLM original.

---

## Tarefa 3.4: Descrever os m√©todos para avaliar o desempenho

A avalia√ß√£o mede se um modelo √© "bom" tanto do ponto de vista t√©cnico quanto do impacto no neg√≥cio.

### Abordagens de Avalia√ß√£o

- **Avalia√ß√£o Humana:** Considerado o "padr√£o ouro". Pessoas avaliam a qualidade das respostas com base em crit√©rios como precis√£o, coer√™ncia e seguran√ßa. √â eficaz, mas lento e caro.

- **Benchmarks (Conjuntos de Dados de Refer√™ncia):** Avalia√ß√£o autom√°tica do modelo em conjuntos de dados padronizados onde as respostas corretas s√£o conhecidas. Permite uma compara√ß√£o objetiva entre diferentes modelos. Exemplos incluem:  
  - GLUE (General Language Understanding Evaluation)  
  - MMLU (Massive Multitask Language Understanding)  
  - HELM (Holistic Evaluation of Language Models)

### M√©tricas de Avalia√ß√£o T√©cnica

- **ROUGE (Recall-Oriented Understudy for Gisting Evaluation):** Usado para avaliar a qualidade de resumos, comparando o texto gerado com um resumo de refer√™ncia.

- **BLEU (Bilingual Evaluation Understudy):** Usado para avaliar a qualidade de tradu√ß√µes autom√°ticas, medindo a semelhan√ßa com tradu√ß√µes humanas.

- **BERTScore:** Uma m√©trica mais avan√ßada que avalia a similaridade sem√¢ntica (de significado) entre o texto gerado e o de refer√™ncia, em vez de apenas contar palavras sobrepostas.

### Avalia√ß√£o de Objetivos de Neg√≥cio

O impacto final √© medido por indicadores de neg√≥cio:

- **Produtividade:** O modelo est√° ajudando os funcion√°rios a economizar tempo ou a completar tarefas mais rapidamente?  

- **Envolvimento dos Usu√°rios:** A satisfa√ß√£o do cliente aumentou? Os usu√°rios est√£o interagindo mais com a aplica√ß√£o?

# Tabelas de Resumo: Dom√≠nio 3 ‚Äì Aplica√ß√£o de Modelos de Base

---

## Tabela 1: Crit√©rios de Sele√ß√£o de Modelos de Base
Esta tabela resume os fatores a serem considerados ao escolher um modelo pr√©-treinado.

| Crit√©rio                     | Descri√ß√£o / Considera√ß√µes |
|-------------------------------|---------------------------|
| Custo e Complexidade          | Avalia o custo por token, de hospedagem e de ajuste fino. Modelos maiores e mais complexos s√£o mais caros e lentos, mas geralmente mais capazes. |
| Modalidade                    | Define se o modelo trabalha com texto, imagem, √°udio (unimodal) ou uma combina√ß√£o deles (multimodal). |
| Lat√™ncia                      | Mede a rapidez com que o modelo responde, um fator cr√≠tico para aplica√ß√µes em tempo real. |
| Janela de Contexto            | Refere-se √† quantidade m√°xima de tokens que o modelo pode processar em uma √∫nica chamada. Um contexto maior permite analisar documentos mais longos ou manter conversas complexas. |
| Capacidade de Personaliza√ß√£o  | Verifica se o modelo permite ajuste fino (fine-tuning) para ser adaptado a tarefas ou dom√≠nios espec√≠ficos. |
| Suporte a Idiomas             | Confirma se o modelo suporta os idiomas necess√°rios para a aplica√ß√£o. |

---

## Tabela 2: Comparativo de M√©todos de Personaliza√ß√£o de Modelos
Esta tabela compara as principais abordagens para adaptar um modelo, do mais simples ao mais complexo.

| M√©todo                          | Custo / Esfor√ßo | Principal Vantagem e Caso de Uso |
|---------------------------------|----------------|---------------------------------|
| Aprendizado em Contexto (Prompting) | O mais baixo. A personaliza√ß√£o ocorre a cada chamada de API. | R√°pido e barato para guiar o comportamento do modelo em tempo real, sem alterar seus pesos. |
| RAG (Retrieval-Augmented Generation) | Moderado. O custo est√° no armazenamento de vetores e chamadas √† base de dados. | Excelente para fornecer conhecimento factual, atualizado e espec√≠fico do dom√≠nio, evitando alucina√ß√µes. |
| Ajuste Fino (Fine-Tuning)       | Alto. Adapta um modelo pr√©-treinado usando um dataset menor e espec√≠fico. | Melhora significativamente o desempenho para tarefas ou dom√≠nios espec√≠ficos (ex: jur√≠dico, m√©dico). |
| Pr√©-treinamento (do zero)       | O mais alto. Exige enormes quantidades de dados e poder computacional. | Oferece personaliza√ß√£o total, mas raramente √© necess√°rio para a maioria das aplica√ß√µes de neg√≥cio. |

---

## Tabela 3: T√©cnicas de Engenharia de Prompts
Um resumo das principais t√©cnicas para criar prompts eficazes.

| T√©cnica                            | Descri√ß√£o |
|-----------------------------------|-----------|
| Zero-shot Prompting               | A tarefa √© solicitada ao modelo sem fornecer nenhum exemplo de como realiz√°-la. |
| Few-shot Prompting                | O prompt inclui um ou alguns exemplos ("shots") de entrada e sa√≠da para guiar o modelo a calibrar sua resposta. |
| Cadeia de Pensamento (CoT - Chain-of-Thought) | O modelo √© instru√≠do a decompor seu racioc√≠nio em etapas intermedi√°rias antes de dar a resposta final, o que melhora o desempenho em tarefas l√≥gicas e matem√°ticas. |

---

## Tabela 4: Riscos e Amea√ßas de Seguran√ßa em Prompts
Principais vulnerabilidades associadas √† engenharia de prompts.

| Risco                        | Descri√ß√£o |
|-------------------------------|-----------|
| Prompt Hijacking (Sequestro) | Um usu√°rio mal-intencionado insere instru√ß√µes no prompt para fazer o modelo ignorar as ordens originais e executar uma tarefa diferente. |
| Jailbreaking                  | Uma tentativa de criar prompts que contornam as barreiras de seguran√ßa (guardrails) do modelo para gerar conte√∫do proibido ou malicioso. |
| Exposi√ß√£o de Dados            | Risco de vazar dados sens√≠veis se eles forem inclu√≠dos no prompt enviado a uma API de terceiros. |
| Prompt Injection              | Ataques de manipula√ß√£o onde uma entrada n√£o confi√°vel de um usu√°rio produz uma resposta maliciosa do modelo. |

---

## Tabela 5: Abordagens de Avalia√ß√£o de Modelos
Comparativo entre os principais m√©todos para avaliar o desempenho de um modelo de base.

| Abordagem         | Descri√ß√£o | Vantagens | Desvantagens |
|------------------|-----------|-----------|--------------|
| Avalia√ß√£o Humana  | Pessoas avaliam a qualidade das respostas do modelo com base em crit√©rios como precis√£o, coer√™ncia e seguran√ßa. | √â o "padr√£o ouro" para medir a qualidade real e o alinhamento com as prefer√™ncias humanas. | √â um processo lento, caro e dif√≠cil de escalar. |
| Benchmarks        | Avalia√ß√£o autom√°tica do modelo em conjuntos de dados padronizados (ex: GLUE, MMLU) onde as respostas corretas s√£o conhecidas. | Permite uma compara√ß√£o objetiva, r√°pida e escal√°vel entre diferentes modelos. | Pode n√£o capturar nuances de qualidade ou o alinhamento com os objetivos espec√≠ficos do neg√≥cio. |

---

## Tabela 6: M√©tricas de Avalia√ß√£o T√©cnica
M√©tricas comuns para medir o desempenho de tarefas espec√≠ficas de IA Generativa.

| M√©trica  | Significado | Principal Caso de Uso |
|----------|------------|---------------------|
| ROUGE    | Recall-Oriented Understudy for Gisting Evaluation | Avaliar a qualidade de resumos de texto gerados automaticamente. |
| BLEU     | Bilingual Evaluation Understudy | Avaliar a qualidade de textos traduzidos por m√°quina. |
| BERTScore | N/A | Avalia a similaridade sem√¢ntica (de significado) entre o texto gerado e o de refer√™ncia. |
