# üìò Dom√≠nio 4 ‚Äì Diretrizes para IA Respons√°vel: Quest√µes de M√∫ltipla Escolha

## üîπ Tarefa 4.1: Desenvolvimento √âtico e Justo de Sistemas de IA

1. O que √© IA Respons√°vel?  
- [ ] Um modelo que sempre gera respostas corretas.  
- [ ] Um conjunto de diretrizes para garantir que sistemas de IA operem de forma √©tica, segura e confi√°vel.  
- [ ] Apenas modelos auditados pelo governo.  
- [ ] Sistemas de IA que n√£o usam dados pessoais.  

2. Qual dimens√£o da IA Respons√°vel garante que todos os indiv√≠duos sejam tratados de forma equitativa?  
- [ ] Explicabilidade  
- [ ] Justi√ßa (Fairness)  
- [ ] Robustez  
- [ ] Governan√ßa  

3. A capacidade de explicar decis√µes do modelo em termos humanos √© chamada de:  
- [ ] Transpar√™ncia  
- [ ] Explicabilidade (Explainability)  
- [ ] Inclus√£o  
- [ ] Veracidade  

4. Garantir que sistemas de IA n√£o falhem e resistam a ataques √© um aspecto de:  
- [ ] Privacidade  
- [ ] Robustez e Seguran√ßa  
- [ ] Transpar√™ncia  
- [ ] Governan√ßa  

5. Proteger informa√ß√µes de identifica√ß√£o pessoal (PII) √© responsabilidade de qual dimens√£o da IA Respons√°vel?  
- [ ] Inclus√£o  
- [ ] Privacidade e Seguran√ßa  
- [ ] Explicabilidade  
- [ ] Justi√ßa  

6. Fornecer informa√ß√µes claras sobre capacidades, limita√ß√µes e riscos do modelo est√° relacionado a:  
- [ ] Transpar√™ncia  
- [ ] Robustez  
- [ ] Inclus√£o  
- [ ] Governan√ßa  

---

## üîπ Tarefa 4.2: Vi√©s e Justi√ßa em Modelos de IA

7. O que ocorre quando um grupo est√° sub-representado nos dados de treinamento?  
- [ ] Overfitting  
- [ ] Desequil√≠brio de Classe  
- [ ] Transpar√™ncia  
- [ ] Governan√ßa  

8. Dados de treinamento que n√£o refletem a diversidade do mundo real podem causar:  
- [ ] Overfitting ou Underfitting  
- [ ] RLHF  
- [ ] Modelos transparentes  
- [ ] Guardrails  

9. Quando um modelo se ajusta demais aos dados de treinamento e falha em generalizar, ocorre:  
- [ ] Underfitting  
- [ ] Overfitting  
- [ ] Inclus√£o  
- [ ] Vi√©s  

10. Um modelo muito simples que n√£o captura padr√µes relevantes apresenta:  
- [ ] Overfitting  
- [ ] Underfitting  
- [ ] Transpar√™ncia  
- [ ] Explicabilidade  

---

## üîπ Tarefa 4.3: Riscos da IA Generativa

11. Quando o modelo gera informa√ß√µes factualmente incorretas, chamamos isso de:  
- [ ] Conte√∫do T√≥xico  
- [ ] Alucina√ß√µes  
- [ ] Viola√ß√£o de PI  
- [ ] Vi√©s  

12. Qual risco ocorre quando o modelo gera conte√∫do muito semelhante a dados protegidos por direitos autorais?  
- [ ] Alucina√ß√µes  
- [ ] Privacidade de Dados  
- [ ] Viola√ß√£o de Propriedade Intelectual  
- [ ] Conte√∫do T√≥xico  

13. Gera√ß√£o de respostas ofensivas ou inadequadas √© um exemplo de:  
- [ ] Viola√ß√£o de PI  
- [ ] Conte√∫do T√≥xico  
- [ ] Alucina√ß√£o  
- [ ] Desequil√≠brio de Classe  

14. Vazamento de dados sens√≠veis como PII se enquadra em qual risco?  
- [ ] Alucina√ß√£o  
- [ ] Privacidade de Dados  
- [ ] Robustez  
- [ ] Transpar√™ncia  

15. Ferramenta AWS para limitar t√≥picos, remover PII e filtrar conte√∫do prejudicial:  
- [ ] Amazon SageMaker Clarify  
- [ ] Guardrails for Amazon Bedrock  
- [ ] Amazon A2I  
- [ ] RLHF  

---

## üîπ Tarefa 4.4: Ferramentas da AWS para Mitiga√ß√£o de Vi√©s

16. Qual ferramenta detecta vi√©s em dados e modelos em diferentes fases do ML?  
- [ ] SageMaker Ground Truth  
- [ ] SageMaker Clarify  
- [ ] Model Cards  
- [ ] AI Service Cards  

17. M√©tricas como desequil√≠brio de classe, disparidade demogr√°fica e diferen√ßa de acur√°cia/recall s√£o fornecidas por:  
- [ ] SageMaker Clarify  
- [ ] Guardrails  
- [ ] Amazon A2I  
- [ ] RLHF  

18. Ferramenta que usa valores de Shapley para explicar a contribui√ß√£o de cada caracter√≠stica na previs√£o:  
- [ ] SageMaker Model Cards  
- [ ] AI Service Cards  
- [ ] Valores de Shapley  
- [ ] SageMaker Ground Truth  

19. Documento que funciona como ‚Äúficha nutricional‚Äù de um modelo, detalhando dados, limita√ß√µes e m√©tricas:  
- [ ] AI Service Cards  
- [ ] SageMaker Model Cards  
- [ ] Clarify Reports  
- [ ] Guardrails  

20. Ferramenta que fornece informa√ß√µes sobre servi√ßos de IA pr√©-treinados da AWS:  
- [ ] AI Service Cards  
- [ ] Model Cards  
- [ ] Guardrails  
- [ ] SageMaker Ground Truth  

---

## üîπ Tarefa 4.5: Transpar√™ncia, Explicabilidade e Human-Centered AI

21. Qual √© a diferen√ßa entre modelos transparentes e explic√°veis?  
- [ ] Transparentes s√£o sempre redes neurais; explic√°veis s√£o regress√µes lineares.  
- [ ] Transparentes t√™m l√≥gica interna clara; explic√°veis s√£o caixas-pretas, mas podem gerar explica√ß√µes.  
- [ ] Transparentes s√£o precisos; explic√°veis s√£o inseguros.  
- [ ] N√£o h√° diferen√ßa.  

22. Trade-off comum em modelos de IA:  
- [ ] Desempenho vs. Transpar√™ncia  
- [ ] Custo vs. Tempo de Infer√™ncia  
- [ ] Privacidade vs. Inclus√£o  
- [ ] Alucina√ß√£o vs. Robustez  

23. Qual t√©cnica permite que humanos revisem infer√™ncias de baixa confian√ßa?  
- [ ] RLHF  
- [ ] Amazon Augmented AI (A2I)  
- [ ] SageMaker Clarify  
- [ ] Guardrails  

24. RLHF significa:  
- [ ] Refor√ßo com L√≥gica Humana Fundamental  
- [ ] Reinforcement Learning from Human Feedback  
- [ ] Regras de L√≥gica e Heur√≠stica Formal  
- [ ] Refor√ßo Limitado por Hardware  

25. Finalidade do RLHF:  
- [ ] Maximizar lucros da empresa  
- [ ] Alinhar LLMs √†s prefer√™ncias humanas, garantindo conte√∫do √∫til e seguro  
- [ ] Garantir que todos os dados sejam p√∫blicos  
- [ ] Substituir revisores humanos  

26. Ferramenta AWS usada para coletar prefer√™ncias humanas e treinar modelos de recompensa:  
- [ ] Amazon SageMaker Ground Truth  
- [ ] SageMaker Clarify  
- [ ] AI Service Cards  
- [ ] Guardrails  

27. Qual t√©cnica/abordagem garante que sistemas de IA priorizem habilidades humanas em vez de substitu√≠-las?  
- [ ] Human-Centered AI  
- [ ] RLHF  
- [ ] Overfitting  
- [ ] Guardrails  

28. Valores de Shapley auxiliam em:  
- [ ] Remo√ß√£o de vi√©s  
- [ ] Explicabilidade e interpreta√ß√£o da import√¢ncia de caracter√≠sticas  
- [ ] Coleta de dados humanos  
- [ ] Preven√ß√£o de alucina√ß√µes  

29. Cart√µes de Modelos (Model Cards) servem para:  
- [ ] Treinar modelos automaticamente  
- [ ] Documentar dados, usos, limita√ß√µes e m√©tricas de desempenho e vi√©s  
- [ ] Ajustar hiperpar√¢metros  
- [ ] Substituir revisores humanos  

30. AI Service Cards ajudam a:  
- [ ] Explicar decis√µes individuais do modelo  
- [ ] Fornecer informa√ß√µes sobre casos de uso e limita√ß√µes de servi√ßos de IA pr√©-treinados  
- [ ] Medir vi√©s de modelos de base  
- [ ] Implementar RLHF automaticamente  
